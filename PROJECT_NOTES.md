# ğŸ“ PROJECT NOTES - FRUIT RECOGNITION 2.0

## ğŸ¯ Tá»”NG QUAN Dá»° ÃN

**TÃªn dá»± Ã¡n**: Fruit Recognition 2.0 - Há»‡ thá»‘ng nháº­n diá»‡n trÃ¡i cÃ¢y thÃ´ng minh  
**Má»¥c tiÃªu**: XÃ¢y dá»±ng á»©ng dá»¥ng web nháº­n diá»‡n 36 loáº¡i quáº£/rau cá»§ báº±ng AI  
**CÃ´ng nghá»‡ chÃ­nh**: CNN (MobileNetV2) + YOLO (YOLOv8) + Flask  

---

## ğŸ—ï¸ KIáº¾N TRÃšC Há»† THá»NG

### Backend (Python/Flask)
- **Framework**: Flask
- **AI Models**: 
  - CNN: `fruit_classifier_mobilenetv2.h5` (MobileNetV2)
  - YOLO: `yolov8n.pt` (YOLOv8 nano)
- **Database**: JSON files (`users.json`, `detection_history.json`)
- **Authentication**: Session-based login

### Frontend (HTML/CSS/JavaScript)
- **Giao diá»‡n**: Responsive design
- **Tabs**: Upload áº¢nh, Webcam, Lá»‹ch sá»­
- **Real-time**: Webcam processing
- **Visualization**: Bounding boxes, charts

---

## ğŸ“ Cáº¤U TRÃšC THÆ¯ Má»¤C

```
fruit_reconige_2.0/
â”œâ”€â”€ app.py                 # Main Flask application
â”œâ”€â”€ train_model.py         # CNN training script
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ yolov8n.pt            # YOLO model file
â”œâ”€â”€ templates/            # HTML templates
â”œâ”€â”€ train/               # Training images (36 classes)
â”œâ”€â”€ validation/          # Validation images
â”œâ”€â”€ test/               # Test images
â”œâ”€â”€ uploads/            # Uploaded images
â””â”€â”€ users.json          # User database
```

---

## ğŸ¤– AI MODELS

### 1. CNN Model (MobileNetV2)

#### **1.1. Äá»‹nh nghÄ©a CNN (Convolutional Neural Network)**
- **CNN** lÃ  kiáº¿n trÃºc máº¡ng nÆ¡-ron chuyÃªn dá»¥ng cho viá»‡c xá»­ lÃ½ dá»¯ liá»‡u cÃ³ cáº¥u trÃºc lÆ°á»›i nhÆ° hÃ¬nh áº£nh
- **NguyÃªn lÃ½ hoáº¡t Ä‘á»™ng**: Sá»­ dá»¥ng cÃ¡c lá»›p tÃ­ch cháº­p (convolutional layers) Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« hÃ¬nh áº£nh
- **Æ¯u Ä‘iá»ƒm**: Tá»± Ä‘á»™ng há»c features, giáº£m tham sá»‘, hiá»‡u quáº£ vá»›i dá»¯ liá»‡u hÃ¬nh áº£nh

#### **1.2. CÃ¡c thÃ nh pháº§n chÃ­nh cá»§a CNN**
- **Convolutional Layer**: Lá»c vÃ  trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« áº£nh
- **Pooling Layer**: Giáº£m kÃ­ch thÆ°á»›c dá»¯ liá»‡u, tÄƒng tÃ­nh báº¥t biáº¿n
- **Fully Connected Layer**: PhÃ¢n loáº¡i cuá»‘i cÃ¹ng
- **Activation Functions**: KÃ­ch hoáº¡t phi tuyáº¿n (ReLU, Softmax)

#### **1.3. Kiáº¿n trÃºc MobileNetV2 trong dá»± Ã¡n**
- **Má»¥c Ä‘Ã­ch**: PhÃ¢n loáº¡i loáº¡i quáº£ chÃ­nh trong áº£nh
- **Input**: 224x224x3 pixels (RGB)
- **Output**: 36 classes vá»›i softmax activation
- **Accuracy**: ~85-90%
- **Sá»­ dá»¥ng**: Upload áº£nh, Webcam capture
- **Transfer Learning**: Sá»­ dá»¥ng pre-trained weights tá»« ImageNet

#### **1.4. QuÃ¡ trÃ¬nh xá»­ lÃ½ CNN**
```
Input Image (224x224x3) 
    â†“
MobileNetV2 Base (Feature Extraction)
    â†“
Global Average Pooling (Reduce dimensions)
    â†“
Dropout (0.3) - Regularization
    â†“
Dense Layer (36 classes)
    â†“
Softmax Activation
    â†“
Output: Class probabilities
```

### 2. YOLO Model (YOLOv8)

#### **2.1. Äá»‹nh nghÄ©a YOLO (You Only Look Once)**
- **YOLO** lÃ  thuáº­t toÃ¡n phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng real-time
- **NguyÃªn lÃ½**: Chia áº£nh thÃ nh grid vÃ  dá»± Ä‘oÃ¡n bounding boxes + class cho má»—i cell
- **Æ¯u Ä‘iá»ƒm**: Tá»‘c Ä‘á»™ nhanh, cÃ³ thá»ƒ phÃ¡t hiá»‡n nhiá»u Ä‘á»‘i tÆ°á»£ng cÃ¹ng lÃºc

#### **2.2. YOLOv8 trong dá»± Ã¡n**
- **Má»¥c Ä‘Ã­ch**: PhÃ¡t hiá»‡n vÃ  Ä‘áº¿m nhiá»u quáº£ trong áº£nh
- **Input**: Any size image (tá»± Ä‘á»™ng resize)
- **Output**: Bounding boxes + class labels + confidence scores
- **Speed**: Real-time (2 FPS)
- **Sá»­ dá»¥ng**: Webcam scan mode
- **Confidence threshold**: 0.25
- **IoU threshold**: 0.45

### 3. Äá»‹nh nghÄ©a Train (Huáº¥n luyá»‡n)

#### **3.1. KhÃ¡i niá»‡m Training**
- **Train** lÃ  quÃ¡ trÃ¬nh dáº¡y mÃ´ hÃ¬nh há»c tá»« dá»¯ liá»‡u Ä‘á»ƒ cÃ³ thá»ƒ dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c
- **Má»¥c tiÃªu**: Tá»‘i Æ°u hÃ³a cÃ¡c tham sá»‘ cá»§a mÃ´ hÃ¬nh Ä‘á»ƒ giáº£m thiá»ƒu loss function
- **Káº¿t quáº£**: MÃ´ hÃ¬nh cÃ³ kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a tá»‘t trÃªn dá»¯ liá»‡u má»›i

#### **3.2. QuÃ¡ trÃ¬nh Training trong dá»± Ã¡n**
```
1. Chuáº©n bá»‹ dá»¯ liá»‡u
   â”œâ”€â”€ Train set (70%): Huáº¥n luyá»‡n mÃ´ hÃ¬nh
   â”œâ”€â”€ Validation set (15%): ÄÃ¡nh giÃ¡ trong quÃ¡ trÃ¬nh train
   â””â”€â”€ Test set (15%): ÄÃ¡nh giÃ¡ cuá»‘i cÃ¹ng

2. Data Augmentation
   â”œâ”€â”€ Rotation (Â±30Â°)
   â”œâ”€â”€ Width/Height shift (Â±10%)
   â”œâ”€â”€ Shear (Â±20%)
   â”œâ”€â”€ Zoom (Â±20%)
   â””â”€â”€ Horizontal flip

3. Model Architecture
   â”œâ”€â”€ Load MobileNetV2 pre-trained
   â”œâ”€â”€ Freeze base layers
   â”œâ”€â”€ Add custom layers
   â””â”€â”€ Compile vá»›i optimizer

4. Training Process
   â”œâ”€â”€ Epochs: 40 (max)
   â”œâ”€â”€ Batch size: 32
   â”œâ”€â”€ Learning rate: 1e-4
   â”œâ”€â”€ Callbacks: Checkpoint, EarlyStopping
   â””â”€â”€ Monitor: validation accuracy

5. Evaluation
   â”œâ”€â”€ Test accuracy
   â”œâ”€â”€ Confusion matrix
   â””â”€â”€ Performance metrics
```

#### **3.3. Transfer Learning Strategy**
- **Base Model**: MobileNetV2 pre-trained trÃªn ImageNet
- **Freeze Strategy**: ÄÃ³ng bÄƒng táº¥t cáº£ layers cá»§a base model
- **Custom Layers**: ThÃªm GlobalAveragePooling2D + Dropout + Dense
- **Fine-tuning**: Chá»‰ train cÃ¡c layer má»›i thÃªm vÃ o
- **Lá»£i Ã­ch**: Táº­n dá»¥ng features Ä‘Ã£ há»c, giáº£m thá»i gian train, tÄƒng accuracy

#### **3.4. Training Parameters**
- **Optimizer**: Adam (learning_rate=1e-4)
- **Loss Function**: Categorical Crossentropy
- **Metrics**: Accuracy
- **Callbacks**:
  - ModelCheckpoint: LÆ°u model tá»‘t nháº¥t
  - EarlyStopping: Dá»«ng sá»›m náº¿u khÃ´ng cáº£i thiá»‡n (patience=7)
- **Data Preprocessing**:
  - Resize: 224x224
  - Normalize: /255.0
  - Augmentation: Chá»‰ Ã¡p dá»¥ng cho train set

#### **3.5. Giáº£i thÃ­ch chi tiáº¿t code train_model.py**

##### **Import vÃ  Setup (DÃ²ng 1-11)**
```python
import tensorflow as tf
from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.models import Model
import matplotlib.pyplot as plt
import os
import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
```
**Giáº£i thÃ­ch tá»«ng import:**
- **tensorflow**: Framework chÃ­nh cho deep learning
- **image_dataset_from_directory**: Äá»c áº£nh tá»« thÆ° má»¥c tá»± Ä‘á»™ng
- **MobileNetV2**: MÃ´ hÃ¬nh CNN pre-trained hiá»‡u quáº£
- **Dense, GlobalAveragePooling2D, Dropout**: CÃ¡c layer neural network
- **Model**: Táº¡o mÃ´ hÃ¬nh tÃ¹y chá»‰nh
- **matplotlib**: Váº½ biá»ƒu Ä‘á»“ káº¿t quáº£
- **ImageDataGenerator**: TÄƒng cÆ°á»ng dá»¯ liá»‡u (data augmentation)
- **Adam**: Optimizer hiá»‡u quáº£
- **ModelCheckpoint, EarlyStopping**: Callbacks Ä‘á»ƒ kiá»ƒm soÃ¡t training

##### **Cáº¥u hÃ¬nh tham sá»‘ (DÃ²ng 13-21)**
```python
train_dir = 'train'
val_dir = 'validation'
test_dir = 'test'

IMG_SIZE = (224, 224)
BATCH_SIZE = 32
EPOCHS = 40
NUM_CLASSES = len(os.listdir('train'))
```
**Giáº£i thÃ­ch:**
- **train_dir, val_dir, test_dir**: ÄÆ°á»ng dáº«n Ä‘áº¿n dá»¯ liá»‡u
- **IMG_SIZE**: KÃ­ch thÆ°á»›c áº£nh Ä‘áº§u vÃ o (224x224 lÃ  chuáº©n cho MobileNetV2)
- **BATCH_SIZE**: Sá»‘ áº£nh xá»­ lÃ½ cÃ¹ng lÃºc (32 lÃ  giÃ¡ trá»‹ cÃ¢n báº±ng)
- **EPOCHS**: Sá»‘ láº§n láº·p qua toÃ n bá»™ dá»¯ liá»‡u train
- **NUM_CLASSES**: Sá»‘ loáº¡i quáº£ (tá»± Ä‘á»™ng Ä‘áº¿m tá»« thÆ° má»¥c)

##### **Äá»c dá»¯ liá»‡u (DÃ²ng 23-41)**
```python
train_ds = image_dataset_from_directory(
    train_dir,
    label_mode='categorical',
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    shuffle=True
)
```
**Giáº£i thÃ­ch:**
- **label_mode='categorical'**: MÃ£ hÃ³a one-hot cho labels
- **image_size=IMG_SIZE**: Resize áº£nh vá» 224x224
- **batch_size=BATCH_SIZE**: Chia dá»¯ liá»‡u thÃ nh batches
- **shuffle=True**: XÃ¡o trá»™n dá»¯ liá»‡u train Ä‘á»ƒ trÃ¡nh overfitting

##### **Data Augmentation (DÃ²ng 51-65)**
```python
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)
```
**Giáº£i thÃ­ch tá»«ng augmentation:**
- **rescale=1./255**: Chuáº©n hÃ³a pixel values vá» [0,1]
- **rotation_range=30**: Xoay áº£nh ngáº«u nhiÃªn Â±30Â°
- **width_shift_range=0.1**: Dá»‹ch chuyá»ƒn ngang Â±10%
- **height_shift_range=0.1**: Dá»‹ch chuyá»ƒn dá»c Â±10%
- **shear_range=0.2**: Biáº¿n dáº¡ng cáº¯t Â±20%
- **zoom_range=0.2**: PhÃ³ng to/thu nhá» Â±20%
- **horizontal_flip=True**: Láº­t ngang áº£nh
- **fill_mode='nearest'**: CÃ¡ch Ä‘iá»n pixel khi biáº¿n Ä‘á»•i

##### **Kiáº¿n trÃºc Model (DÃ²ng 84-92)**
```python
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base_model.trainable = False  # Freeze base

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.3)(x)
predictions = Dense(NUM_CLASSES, activation='softmax')(x)
model = Model(inputs=base_model.input, outputs=predictions)
```
**Giáº£i thÃ­ch tá»«ng layer:**
- **MobileNetV2**: Load pre-trained model tá»« ImageNet
- **include_top=False**: KhÃ´ng bao gá»“m classification layer cuá»‘i
- **base_model.trainable = False**: ÄÃ³ng bÄƒng weights cá»§a base model
- **GlobalAveragePooling2D**: Giáº£m kÃ­ch thÆ°á»›c feature map
- **Dropout(0.3)**: Regularization Ä‘á»ƒ trÃ¡nh overfitting
- **Dense(NUM_CLASSES, activation='softmax')**: Layer phÃ¢n loáº¡i cuá»‘i
- **Model**: Táº¡o model hoÃ n chá»‰nh tá»« input Ä‘áº¿n output

##### **Compile vÃ  Callbacks (DÃ²ng 94-99)**
```python
model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])

checkpoint = ModelCheckpoint('fruit_classifier_mobilenetv2.h5', monitor='val_accuracy', save_best_only=True, verbose=1)
earlystop = EarlyStopping(monitor='val_accuracy', patience=7, restore_best_weights=True)
```
**Giáº£i thÃ­ch:**
- **Adam optimizer**: Optimizer hiá»‡u quáº£ vá»›i learning rate tháº¥p
- **categorical_crossentropy**: Loss function cho multi-class classification
- **ModelCheckpoint**: LÆ°u model tá»‘t nháº¥t dá»±a trÃªn validation accuracy
- **EarlyStopping**: Dá»«ng train sá»›m náº¿u khÃ´ng cáº£i thiá»‡n trong 7 epochs

##### **Training Process (DÃ²ng 101-108)**
```python
history = model.fit(
    train_generator,
    epochs=EPOCHS,
    validation_data=val_generator,
    callbacks=[checkpoint, earlystop]
)
```
**Giáº£i thÃ­ch:**
- **train_generator**: Dá»¯ liá»‡u train vá»›i augmentation
- **validation_data**: Dá»¯ liá»‡u validation Ä‘á»ƒ monitor
- **callbacks**: CÃ¡c callback Ä‘Ã£ Ä‘á»‹nh nghÄ©a
- **history**: LÆ°u trá»¯ metrics trong quÃ¡ trÃ¬nh train

#### **3.6. Giáº£i thÃ­ch code CNN trong app.py**

##### **FruitClassifier Class (DÃ²ng 351-397)**
```python
class FruitClassifier:
    def __init__(self, model_path='fruit_classifier_mobilenetv2.h5'):
        self.model = load_model(model_path)
        self.class_names = [
            'apple', 'banana', 'beetroot', 'bell pepper', 'cabbage', 'capsicum',
            'carrot', 'cauliflower', 'chilli pepper', 'corn', 'cucumber', 'eggplant',
            'garlic', 'ginger', 'grapes', 'jalepeno', 'kiwi', 'lemon', 'lettuce',
            'mango', 'onion', 'orange', 'paprika', 'pear', 'peas', 'pineapple',
            'pomegranate', 'potato', 'raddish', 'soy beans', 'spinach', 'sweetcorn',
            'sweetpotato', 'tomato', 'turnip', 'watermelon'
        ]

    def preprocess_image(self, img):
        img = cv2.resize(img, (224, 224))
        img = img / 255.0
        img = np.expand_dims(img, axis=0)
        return img

    def predict(self, img):
        preprocessed_img = self.preprocess_image(img)
        predictions = self.model.predict(preprocessed_img)
        predicted_class = self.class_names[np.argmax(predictions[0])]
        confidence = float(np.max(predictions[0]))
        return predicted_class, confidence
```

**Giáº£i thÃ­ch tá»«ng method:**

###### **__init__ method (DÃ²ng 352-358)**
- **load_model()**: Load mÃ´ hÃ¬nh Ä‘Ã£ train tá»« file .h5
- **class_names**: Danh sÃ¡ch tÃªn 36 loáº¡i quáº£ theo thá»© tá»±
- **LÆ°u Ã½**: Thá»© tá»± class_names pháº£i khá»›p vá»›i thá»© tá»± trong training

###### **preprocess_image method (DÃ²ng 362-366)**
```python
def preprocess_image(self, img):
    img = cv2.resize(img, (224, 224))      # Resize vá» kÃ­ch thÆ°á»›c chuáº©n
    img = img / 255.0                      # Normalize vá» [0,1]
    img = np.expand_dims(img, axis=0)      # ThÃªm batch dimension
    return img
```
**Giáº£i thÃ­ch tá»«ng bÆ°á»›c:**
- **cv2.resize()**: Thay Ä‘á»•i kÃ­ch thÆ°á»›c áº£nh vá» 224x224 (chuáº©n MobileNetV2)
- **img / 255.0**: Chuáº©n hÃ³a pixel values tá»« [0,255] vá» [0,1]
- **np.expand_dims()**: ThÃªm dimension batch (tá»« (224,224,3) thÃ nh (1,224,224,3))

###### **predict method (DÃ²ng 368-373)**
```python
def predict(self, img):
    preprocessed_img = self.preprocess_image(img)           # Tiá»n xá»­ lÃ½ áº£nh
    predictions = self.model.predict(preprocessed_img)      # Dá»± Ä‘oÃ¡n
    predicted_class = self.class_names[np.argmax(predictions[0])]  # Láº¥y class cÃ³ xÃ¡c suáº¥t cao nháº¥t
    confidence = float(np.max(predictions[0]))              # Láº¥y confidence score
    return predicted_class, confidence
```
**Giáº£i thÃ­ch tá»«ng bÆ°á»›c:**
- **model.predict()**: Cháº¡y inference trÃªn mÃ´ hÃ¬nh CNN
- **np.argmax()**: TÃ¬m index cá»§a class cÃ³ xÃ¡c suáº¥t cao nháº¥t
- **class_names[index]**: Láº¥y tÃªn class tÆ°Æ¡ng á»©ng
- **np.max()**: Láº¥y confidence score cao nháº¥t

##### **Sá»­ dá»¥ng CNN trong Upload (DÃ²ng 465-530)**
```python
@app.route('/upload', methods=['POST'])
@login_required
def upload_file():
    if 'file' not in request.files:
        return jsonify({'error': 'No file uploaded'})
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'No file selected'})
    
    if file and allowed_file(file.filename):
        # Äá»c vÃ  xá»­ lÃ½ áº£nh
        img = cv2.imdecode(np.frombuffer(file.read(), np.uint8), cv2.IMREAD_COLOR)
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # Dá»± Ä‘oÃ¡n báº±ng CNN
        classifier = FruitClassifier()
        predicted_class, confidence = classifier.predict(img_rgb)
        
        # Láº¥y thÃ´ng tin dinh dÆ°á»¡ng
        fruit_info = FRUIT_INFO.get(predicted_class, {})
        
        # LÆ°u lá»‹ch sá»­
        update_stats(predicted_class, confidence, img_base64, "upload", session.get('user_id'))
        
        return jsonify({
            'success': True,
            'predicted_class': predicted_class,
            'confidence': confidence,
            'fruit_info': fruit_info
        })
```

**Giáº£i thÃ­ch quy trÃ¬nh:**
1. **Validate file**: Kiá»ƒm tra file upload há»£p lá»‡
2. **Äá»c áº£nh**: Chuyá»ƒn Ä‘á»•i file thÃ nh numpy array
3. **Chuyá»ƒn mÃ u**: BGR â†’ RGB (OpenCV sá»­ dá»¥ng BGR, CNN cáº§n RGB)
4. **Dá»± Ä‘oÃ¡n**: Sá»­ dá»¥ng FruitClassifier Ä‘á»ƒ phÃ¢n loáº¡i
5. **Láº¥y thÃ´ng tin**: Tra cá»©u thÃ´ng tin dinh dÆ°á»¡ng
6. **LÆ°u lá»‹ch sá»­**: Ghi láº¡i káº¿t quáº£ detection
7. **Tráº£ káº¿t quáº£**: JSON response cho frontend

##### **Sá»­ dá»¥ng CNN trong Webcam (DÃ²ng 531-582)**
```python
@app.route('/webcam', methods=['POST'])
@login_required
def webcam_detection():
    # Nháº­n áº£nh tá»« webcam (base64)
    data = request.get_json()
    img_data = data['image'].split(',')[1]
    img_bytes = base64.b64decode(img_data)
    
    # Chuyá»ƒn Ä‘á»•i thÃ nh numpy array
    img = cv2.imdecode(np.frombuffer(img_bytes, np.uint8), cv2.IMREAD_COLOR)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    # Dá»± Ä‘oÃ¡n báº±ng CNN
    classifier = FruitClassifier()
    predicted_class, confidence = classifier.predict(img_rgb)
    
    # Xá»­ lÃ½ káº¿t quáº£ tÆ°Æ¡ng tá»± upload
```

**Giáº£i thÃ­ch:**
- **Base64 decode**: Chuyá»ƒn Ä‘á»•i áº£nh tá»« base64 string vá» bytes
- **cv2.imdecode()**: Chuyá»ƒn bytes thÃ nh numpy array
- **Quy trÃ¬nh tÆ°Æ¡ng tá»± upload**: Sá»­ dá»¥ng cÃ¹ng CNN classifier

#### **3.7. So sÃ¡nh CNN vÃ  YOLO trong dá»± Ã¡n**

| TiÃªu chÃ­ | CNN (MobileNetV2) | YOLO (YOLOv8) |
|----------|-------------------|---------------|
| **Má»¥c Ä‘Ã­ch** | PhÃ¢n loáº¡i loáº¡i quáº£ chÃ­nh | PhÃ¡t hiá»‡n nhiá»u quáº£ cÃ¹ng lÃºc |
| **Input** | 224x224x3 (cá»‘ Ä‘á»‹nh) | Any size (tá»± Ä‘á»™ng resize) |
| **Output** | Class + Confidence | Bounding boxes + Classes + Confidence |
| **Tá»‘c Ä‘á»™** | ~100ms per image | ~50ms per image |
| **Äá»™ chÃ­nh xÃ¡c** | 85-90% | 70-80% |
| **Sá»­ dá»¥ng** | Upload áº£nh, Webcam capture | Webcam scan mode |
| **Æ¯u Ä‘iá»ƒm** | Äá»™ chÃ­nh xÃ¡c cao, Ä‘Æ¡n giáº£n | Real-time, phÃ¡t hiá»‡n nhiá»u Ä‘á»‘i tÆ°á»£ng |
| **NhÆ°á»£c Ä‘iá»ƒm** | Chá»‰ phÃ¢n loáº¡i 1 quáº£ chÃ­nh | Äá»™ chÃ­nh xÃ¡c tháº¥p hÆ¡n |

#### **3.8. TÃ³m táº¯t quy trÃ¬nh hoÃ n chá»‰nh**

##### **Training Phase:**
1. **Data Preparation**: Chia dá»¯ liá»‡u thÃ nh train/validation/test
2. **Data Augmentation**: TÄƒng cÆ°á»ng dá»¯ liá»‡u train
3. **Model Architecture**: MobileNetV2 + custom layers
4. **Transfer Learning**: Sá»­ dá»¥ng pre-trained weights
5. **Training**: Adam optimizer, categorical crossentropy
6. **Evaluation**: Test accuracy, confusion matrix

##### **Inference Phase:**
1. **Image Preprocessing**: Resize, normalize, expand dimensions
2. **Model Prediction**: Forward pass qua CNN
3. **Post-processing**: Argmax Ä‘á»ƒ láº¥y class, max Ä‘á»ƒ láº¥y confidence
4. **Result Display**: Hiá»ƒn thá»‹ káº¿t quáº£ + thÃ´ng tin dinh dÆ°á»¡ng
5. **History Logging**: LÆ°u káº¿t quáº£ vÃ o database

##### **Key Technical Points:**
- **Transfer Learning**: Táº­n dá»¥ng MobileNetV2 pre-trained
- **Data Augmentation**: TÄƒng robustness cá»§a model
- **Regularization**: Dropout Ä‘á»ƒ trÃ¡nh overfitting
- **Early Stopping**: TrÃ¡nh overfitting, tá»‘i Æ°u training time
- **Model Checkpointing**: LÆ°u model tá»‘t nháº¥t
- **Batch Processing**: Xá»­ lÃ½ nhiá»u áº£nh cÃ¹ng lÃºc
- **Memory Optimization**: Prefetch Ä‘á»ƒ tÄƒng hiá»‡u suáº¥t

---

## ğŸ”§ CÃC CHá»¨C NÄ‚NG CHÃNH

### 1. Há»‡ thá»‘ng Authentication
- âœ… ÄÄƒng kÃ½ tÃ i khoáº£n
- âœ… ÄÄƒng nháº­p/ÄÄƒng xuáº¥t
- âœ… QuÃªn máº­t kháº©u
- âœ… Session management

### 2. Nháº­n diá»‡n qua Upload
- âœ… Upload file áº£nh (JPG, PNG)
- âœ… CNN classification
- âœ… Hiá»ƒn thá»‹ káº¿t quáº£ + confidence
- âœ… ThÃ´ng tin dinh dÆ°á»¡ng

### 3. Nháº­n diá»‡n qua Webcam
- âœ… Truy cáº­p camera
- âœ… Real-time YOLO detection
- âœ… Bounding boxes visualization
- âœ… Äáº¿m sá»‘ lÆ°á»£ng quáº£

### 4. Quáº£n lÃ½ lá»‹ch sá»­
- âœ… LÆ°u táº¥t cáº£ detections
- âœ… Thá»‘ng kÃª theo ngÃ y/loáº¡i quáº£
- âœ… Export Excel
- âœ… XÃ³a lá»‹ch sá»­

---

## ğŸ“‹ Äá»ŠNH NGHÄ¨A CHI TIáº¾T CÃC CHá»¨C NÄ‚NG

### ğŸ” **1. Há»† THá»NG AUTHENTICATION**

#### **1.1. ÄÄƒng kÃ½ tÃ i khoáº£n (Register)**
- **Äá»‹nh nghÄ©a**: Cho phÃ©p ngÆ°á»i dÃ¹ng táº¡o tÃ i khoáº£n má»›i
- **Chá»©c nÄƒng**:
  - Nháº­p username vÃ  password
  - Validate thÃ´ng tin (username khÃ´ng trÃ¹ng, password Ä‘á»§ máº¡nh)
  - MÃ£ hÃ³a password báº±ng SHA-256
  - LÆ°u thÃ´ng tin vÃ o `users.json`
- **Báº£o máº­t**: Password Ä‘Æ°á»£c hash trÆ°á»›c khi lÆ°u

#### **1.2. ÄÄƒng nháº­p (Login)**
- **Äá»‹nh nghÄ©a**: XÃ¡c thá»±c ngÆ°á»i dÃ¹ng Ä‘á»ƒ truy cáº­p há»‡ thá»‘ng
- **Chá»©c nÄƒng**:
  - Kiá»ƒm tra username/password
  - Táº¡o session cho ngÆ°á»i dÃ¹ng
  - Redirect Ä‘áº¿n trang chá»§ sau khi Ä‘Äƒng nháº­p thÃ nh cÃ´ng
- **Session**: LÆ°u tráº¡ng thÃ¡i Ä‘Äƒng nháº­p trong 24 giá»

#### **1.3. ÄÄƒng xuáº¥t (Logout)**
- **Äá»‹nh nghÄ©a**: Káº¿t thÃºc phiÃªn lÃ m viá»‡c cá»§a ngÆ°á»i dÃ¹ng
- **Chá»©c nÄƒng**: XÃ³a session vÃ  redirect vá» trang Ä‘Äƒng nháº­p

#### **1.4. QuÃªn máº­t kháº©u (Forgot Password)**
- **Äá»‹nh nghÄ©a**: KhÃ´i phá»¥c máº­t kháº©u khi ngÆ°á»i dÃ¹ng quÃªn
- **Chá»©c nÄƒng**: Reset password vá» máº·c Ä‘á»‹nh (cáº§n cáº£i thiá»‡n)

### ğŸ“¤ **2. NHáº¬N DIá»†N QUA UPLOAD**

#### **2.1. Upload File**
- **Äá»‹nh nghÄ©a**: Táº£i lÃªn áº£nh tá»« thiáº¿t bá»‹ Ä‘á»ƒ phÃ¢n tÃ­ch
- **Chá»©c nÄƒng**:
  - Há»— trá»£ format JPG, PNG
  - Giá»›i háº¡n kÃ­ch thÆ°á»›c 16MB
  - Validate file trÆ°á»›c khi xá»­ lÃ½
  - LÆ°u áº£nh vÃ o thÆ° má»¥c `uploads/`

#### **2.2. CNN Classification**
- **Äá»‹nh nghÄ©a**: PhÃ¢n loáº¡i loáº¡i quáº£ chÃ­nh trong áº£nh báº±ng CNN
- **Chá»©c nÄƒng**:
  - Tiá»n xá»­ lÃ½ áº£nh (resize 224x224, normalize)
  - Dá»± Ä‘oÃ¡n báº±ng model MobileNetV2
  - Tráº£ vá» tÃªn quáº£ vÃ  Ä‘á»™ tin cáº­y (confidence)
- **Äá»™ chÃ­nh xÃ¡c**: 85-90%

#### **2.3. Hiá»ƒn thá»‹ káº¿t quáº£**
- **Äá»‹nh nghÄ©a**: TrÃ¬nh bÃ y káº¿t quáº£ nháº­n diá»‡n cho ngÆ°á»i dÃ¹ng
- **Chá»©c nÄƒng**:
  - Hiá»ƒn thá»‹ áº£nh gá»‘c
  - TÃªn quáº£ (tiáº¿ng Anh vÃ  tiáº¿ng Viá»‡t)
  - Äá»™ tin cáº­y dÆ°á»›i dáº¡ng pháº§n trÄƒm
  - ThÃ´ng tin dinh dÆ°á»¡ng chi tiáº¿t

### ğŸ“¹ **3. NHáº¬N DIá»†N QUA WEBCAM**

#### **3.1. Truy cáº­p Camera**
- **Äá»‹nh nghÄ©a**: Káº¿t ná»‘i vá»›i camera cá»§a thiáº¿t bá»‹
- **Chá»©c nÄƒng**:
  - YÃªu cáº§u quyá»n truy cáº­p camera
  - Hiá»ƒn thá»‹ video stream real-time
  - Há»— trá»£ camera trÆ°á»›c/sau
- **Äá»™ phÃ¢n giáº£i**: 640x480 (tá»‘i Æ°u)

#### **3.2. Cháº¿ Ä‘á»™ Scan (YOLO)**
- **Äá»‹nh nghÄ©a**: PhÃ¡t hiá»‡n liÃªn tá»¥c nhiá»u quáº£ trong khung hÃ¬nh
- **Chá»©c nÄƒng**:
  - Tá»± Ä‘á»™ng scan má»—i 500ms (2 FPS)
  - PhÃ¡t hiá»‡n bounding boxes cho tá»«ng quáº£
  - Äáº¿m sá»‘ lÆ°á»£ng má»—i loáº¡i quáº£
  - Hiá»ƒn thá»‹ overlay thÃ´ng tin
- **Model**: YOLOv8 vá»›i confidence threshold 0.25

#### **3.3. Cháº¿ Ä‘á»™ Capture (CNN)**
- **Äá»‹nh nghÄ©a**: Chá»¥p áº£nh vÃ  phÃ¢n tÃ­ch báº±ng CNN
- **Chá»©c nÄƒng**:
  - Chá»¥p áº£nh tá»« webcam
  - PhÃ¢n loáº¡i loáº¡i quáº£ chÃ­nh
  - Hiá»ƒn thá»‹ káº¿t quáº£ chi tiáº¿t
- **Model**: MobileNetV2

#### **3.4. Bounding Boxes Visualization**
- **Äá»‹nh nghÄ©a**: Váº½ khung vÃ  nhÃ£n cho cÃ¡c quáº£ Ä‘Æ°á»£c phÃ¡t hiá»‡n
- **Chá»©c nÄƒng**:
  - Váº½ rectangle xung quanh quáº£
  - Hiá»ƒn thá»‹ tÃªn quáº£ vÃ  confidence
  - MÃ u sáº¯c khÃ¡c nhau cho tá»«ng loáº¡i quáº£

### ğŸ“Š **4. QUáº¢N LÃ Lá»ŠCH Sá»¬**

#### **4.1. LÆ°u trá»¯ Detection History**
- **Äá»‹nh nghÄ©a**: Ghi láº¡i táº¥t cáº£ cÃ¡c láº§n nháº­n diá»‡n
- **Chá»©c nÄƒng**:
  - LÆ°u thÃ´ng tin: thá»i gian, loáº¡i quáº£, confidence
  - LÆ°u áº£nh dÆ°á»›i dáº¡ng base64
  - PhÃ¢n loáº¡i theo loáº¡i detection (upload/webcam/yolo)
  - LiÃªn káº¿t vá»›i user ID

#### **4.2. Thá»‘ng kÃª tá»•ng quan**
- **Äá»‹nh nghÄ©a**: Hiá»ƒn thá»‹ sá»‘ liá»‡u tá»•ng há»£p vá» hoáº¡t Ä‘á»™ng
- **Chá»©c nÄƒng**:
  - Tá»•ng sá»‘ láº§n nháº­n diá»‡n
  - Sá»‘ loáº¡i quáº£ khÃ¡c nhau Ä‘Ã£ phÃ¡t hiá»‡n
  - Biá»ƒu Ä‘á»“ theo thá»i gian
  - Top loáº¡i quáº£ Ä‘Æ°á»£c nháº­n diá»‡n nhiá»u nháº¥t

#### **4.3. Thá»‘ng kÃª chi tiáº¿t**
- **Äá»‹nh nghÄ©a**: PhÃ¢n tÃ­ch sÃ¢u vá» dá»¯ liá»‡u nháº­n diá»‡n
- **Chá»©c nÄƒng**:
  - Thá»‘ng kÃª theo ngÃ y/tuáº§n/thÃ¡ng
  - PhÃ¢n tÃ­ch theo loáº¡i quáº£
  - Äá»™ tin cáº­y trung bÃ¬nh
  - So sÃ¡nh hiá»‡u suáº¥t cÃ¡c model

#### **4.4. Export Excel**
- **Äá»‹nh nghÄ©a**: Xuáº¥t dá»¯ liá»‡u lá»‹ch sá»­ ra file Excel
- **Chá»©c nÄƒng**:
  - Táº¡o file .xlsx vá»›i Ä‘áº§y Ä‘á»§ thÃ´ng tin
  - Bao gá»“m: thá»i gian, loáº¡i quáº£, confidence, áº£nh
  - Há»— trá»£ filter vÃ  sort
- **Format**: Pandas DataFrame â†’ Excel

#### **4.5. XÃ³a lá»‹ch sá»­**
- **Äá»‹nh nghÄ©a**: XÃ³a cÃ¡c báº£n ghi lá»‹ch sá»­
- **Chá»©c nÄƒng**:
  - XÃ³a tá»«ng báº£n ghi riÃªng láº»
  - XÃ³a táº¥t cáº£ lá»‹ch sá»­
  - XÃ¡c nháº­n trÆ°á»›c khi xÃ³a
- **Báº£o máº­t**: Chá»‰ user sá»Ÿ há»¯u má»›i Ä‘Æ°á»£c xÃ³a

### ğŸ **5. THÃ”NG TIN DINH DÆ¯á» NG**

#### **5.1. Database thÃ´ng tin quáº£**
- **Äá»‹nh nghÄ©a**: CÆ¡ sá»Ÿ dá»¯ liá»‡u thÃ´ng tin chi tiáº¿t vá» tá»«ng loáº¡i quáº£
- **Chá»©c nÄƒng**:
  - TÃªn tiáº¿ng Viá»‡t
  - Calories/100g
  - Danh sÃ¡ch vitamin
  - Lá»£i Ã­ch sá»©c khá»e
  - MÃ u sáº¯c hiá»ƒn thá»‹

#### **5.2. Hiá»ƒn thá»‹ thÃ´ng tin**
- **Äá»‹nh nghÄ©a**: TrÃ¬nh bÃ y thÃ´ng tin dinh dÆ°á»¡ng cho ngÆ°á»i dÃ¹ng
- **Chá»©c nÄƒng**:
  - Card thÃ´ng tin Ä‘áº¹p máº¯t
  - Tags vitamin vá»›i mÃ u sáº¯c
  - MÃ´ táº£ lá»£i Ã­ch sá»©c khá»e
  - Responsive design

### ğŸ”§ **6. CÃC CHá»¨C NÄ‚NG PHá»¤ TRá»¢**

#### **6.1. Session Management**
- **Äá»‹nh nghÄ©a**: Quáº£n lÃ½ phiÃªn lÃ m viá»‡c cá»§a ngÆ°á»i dÃ¹ng
- **Chá»©c nÄƒng**:
  - Táº¡o session khi Ä‘Äƒng nháº­p
  - Kiá»ƒm tra session cho cÃ¡c trang báº£o vá»‡
  - Tá»± Ä‘á»™ng logout sau thá»i gian timeout
- **Báº£o máº­t**: Secret key cho session

#### **6.2. File Management**
- **Äá»‹nh nghÄ©a**: Quáº£n lÃ½ file upload vÃ  lÆ°u trá»¯
- **Chá»©c nÄƒng**:
  - Validate file type vÃ  size
  - Táº¡o tÃªn file unique
  - LÆ°u trá»¯ cÃ³ tá»• chá»©c
  - Cleanup file cÅ©

#### **6.3. Error Handling**
- **Äá»‹nh nghÄ©a**: Xá»­ lÃ½ lá»—i vÃ  thÃ´ng bÃ¡o cho ngÆ°á»i dÃ¹ng
- **Chá»©c nÄƒng**:
  - Catch vÃ  log lá»—i
  - Hiá»ƒn thá»‹ thÃ´ng bÃ¡o thÃ¢n thiá»‡n
  - Fallback khi model lá»—i
  - Debug information

#### **6.4. Responsive Design**
- **Äá»‹nh nghÄ©a**: Giao diá»‡n thÃ­ch á»©ng vá»›i má»i thiáº¿t bá»‹
- **Chá»©c nÄƒng**:
  - Mobile-first design
  - Flexible layout
  - Touch-friendly interface
  - Cross-browser compatibility

---

## ğŸ“Š Dá»® LIá»†U VÃ€ THÃ”NG TIN

### 36 Loáº¡i Quáº£/Rau Cá»§
1. apple, banana, beetroot, bell pepper
2. cabbage, capsicum, carrot, cauliflower
3. chilli pepper, corn, cucumber, eggplant
4. garlic, ginger, grapes, jalepeno
5. kiwi, lemon, lettuce, mango
6. onion, orange, paprika, pear
7. peas, pineapple, pomegranate, potato
8. raddish, soy beans, spinach, sweetcorn
9. sweetpotato, tomato, turnip, watermelon

### ThÃ´ng tin dinh dÆ°á»¡ng cho má»—i loáº¡i:
- TÃªn tiáº¿ng Viá»‡t
- Calories/100g
- Danh sÃ¡ch vitamin
- Lá»£i Ã­ch sá»©c khá»e
- MÃ u sáº¯c hiá»ƒn thá»‹

---

## ğŸš€ CÃCH CHáº Y Dá»° ÃN

### 1. CÃ i Ä‘áº·t dependencies
```bash
pip install -r requirements.txt
```

### 2. Chuáº©n bá»‹ dá»¯ liá»‡u
- Äáº·t áº£nh training vÃ o thÆ° má»¥c `train/`
- Äáº·t áº£nh validation vÃ o thÆ° má»¥c `validation/`
- Äáº·t áº£nh test vÃ o thÆ° má»¥c `test/`

### 3. Train CNN model (náº¿u cáº§n)
```bash
python train_model.py
```

### 4. Cháº¡y á»©ng dá»¥ng
```bash
python app.py
# hoáº·c
python run_webapp.py
```

### 5. Truy cáº­p
- URL: http://localhost:5000
- ÄÄƒng kÃ½ tÃ i khoáº£n má»›i hoáº·c Ä‘Äƒng nháº­p

---

## ğŸ” API ENDPOINTS

### Authentication
- `GET /` - Trang chá»§ (yÃªu cáº§u login)
- `GET /login` - Trang Ä‘Äƒng nháº­p
- `POST /login` - Xá»­ lÃ½ Ä‘Äƒng nháº­p
- `GET /logout` - ÄÄƒng xuáº¥t
- `GET /register` - Trang Ä‘Äƒng kÃ½
- `POST /register` - Xá»­ lÃ½ Ä‘Äƒng kÃ½

### Detection
- `POST /upload` - Upload áº£nh (CNN)
- `POST /webcam` - Webcam capture (CNN)
- `POST /yolo-detect` - YOLO detection

### History & Stats
- `GET /history` - Lá»‹ch sá»­ detections
- `GET /stats` - Thá»‘ng kÃª tá»•ng quan
- `GET /history-stats` - Thá»‘ng kÃª chi tiáº¿t
- `POST /delete_history` - XÃ³a lá»‹ch sá»­
- `GET /export_history_excel` - Export Excel

---

## âš™ï¸ Cáº¤U HÃŒNH QUAN TRá»ŒNG

### Model Paths
- CNN Model: `fruit_classifier_mobilenetv2.h5`
- YOLO Model: `yolov8n.pt`

### Image Settings
- Max file size: 16MB
- Supported formats: JPG, PNG
- CNN input size: 224x224
- YOLO: Any size

### Webcam Settings
- Resolution: 640x480 (ideal)
- Scan interval: 500ms (2 FPS)
- Confidence threshold: 0.25 (YOLO)

---

## ğŸ› TROUBLESHOOTING

### Lá»—i thÆ°á»ng gáº·p:
1. **Model khÃ´ng load**: Kiá»ƒm tra file model tá»“n táº¡i
2. **Webcam khÃ´ng hoáº¡t Ä‘á»™ng**: Kiá»ƒm tra quyá»n truy cáº­p camera
3. **Upload lá»—i**: Kiá»ƒm tra Ä‘á»‹nh dáº¡ng file vÃ  kÃ­ch thÆ°á»›c
4. **Memory error**: Giáº£m batch size hoáº·c image size

### Debug tips:
- Kiá»ƒm tra console logs
- Xem Flask debug output
- Test tá»«ng component riÃªng láº»

---

## ğŸ“ˆ METRICS VÃ€ ÄÃNH GIÃ

### Model Performance
- CNN Accuracy: ~85-90%
- YOLO mAP: ~70-80%
- Inference time: <1s per image

### User Experience
- Response time: <2s
- UI/UX: Intuitive
- Mobile friendly: Yes

---

## ğŸ”® PHÃT TRIá»‚N TÆ¯Æ NG LAI

### TÃ­nh nÄƒng cÃ³ thá»ƒ thÃªm:
1. **Mobile App**: React Native/Flutter
2. **Cloud Deployment**: AWS/Azure
3. **Database**: PostgreSQL/MongoDB
4. **Real-time API**: WebSocket
5. **Multi-language**: English, Chinese
6. **Advanced Analytics**: ML insights
7. **Barcode Integration**: Product lookup
8. **Social Features**: Share results

### Cáº£i thiá»‡n AI:
1. **More classes**: 100+ fruit types
2. **Better accuracy**: Ensemble models
3. **Faster inference**: Model optimization
4. **Edge deployment**: TensorFlow Lite

---

## ğŸ“š TÃ€I LIá»†U THAM KHáº¢O

### Technologies
- Flask Documentation
- TensorFlow/Keras Guides
- YOLOv8 Documentation
- OpenCV Tutorials

### Research Papers
- MobileNetV2: Inverted Residuals and Linear Bottlenecks
- YOLOv8: You Only Look Once v8
- Transfer Learning for Image Classification

---

## ğŸ‘¥ TEAM & CONTRIBUTION

**Developer**: [Your Name]  
**Version**: 2.0  
**Last Updated**: [Date]  
**License**: MIT  

---



